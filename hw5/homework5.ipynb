{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45bb5c4d",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc21fdfe-8a9f-4a0e-b7ff-017e608b5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21296637-cc05-4d6b-8ce3-2fe714f66575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18aed2a0-1eda-4338-9bf4-c1da137a2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae72314",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea25593",
   "metadata": {},
   "source": [
    "Starting Spark session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f02ec1d-b192-4b7a-8d3f-834df24daa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/22 09:40:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e32525",
   "metadata": {},
   "source": [
    "Checking Spark version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c27583-bb30-4fc3-a615-c525d68d0940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc53ec7",
   "metadata": {},
   "source": [
    "Using environment with Python 3.10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8120889-95a2-4295-a6fe-a479bc2b1ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.14 (main, Mar 21 2024, 16:24:04) [GCC 11.2.0]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c3ebd6",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1bbc4e",
   "metadata": {},
   "source": [
    "Extracting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0795f3ba-4a4d-47c0-8b62-03faaf5aaba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-21 12:34:35--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n",
      "Resolving github.com (github.com)... 192.30.255.112\n",
      "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240321%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240321T123435Z&X-Amz-Expires=300&X-Amz-Signature=6daf8a5b6d13b9bb9bf47a27630e16e498c4e17b7d8c044bb5d3d67ed67266cf&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-21 12:34:36--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240321%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240321T123435Z&X-Amz-Expires=300&X-Amz-Signature=6daf8a5b6d13b9bb9bf47a27630e16e498c4e17b7d8c044bb5d3d67ed67266cf&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19375751 (18M) [application/octet-stream]\n",
      "Saving to: ‘fhv_tripdata_2019-10.csv.gz’\n",
      "\n",
      "fhv_tripdata_2019-1 100%[===================>]  18.48M  60.4MB/s    in 0.3s    \n",
      "\n",
      "2024-03-21 12:34:36 (60.4 MB/s) - ‘fhv_tripdata_2019-10.csv.gz’ saved [19375751/19375751]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4de032d-4d75-45b0-9454-c22cbb4cb9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -d fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b26c59ef-eea3-4f49-a6af-75fe373b782f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1897494 fhv_tripdata_2019-10.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l fhv_tripdata_2019-10.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654709ab",
   "metadata": {},
   "source": [
    "Reading data into Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a15c26e-5081-4f31-a78a-ff4dc6e95bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('fhv_tripdata_2019-10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b85399d",
   "metadata": {},
   "source": [
    "Checking schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b11aaab-0700-459a-988c-f92d4fd44780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', StringType(), True), StructField('DOlocationID', StringType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fa7512",
   "metadata": {},
   "source": [
    "Using Pandas to infer datatypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d48d96d5-d4dc-4a9b-b6a2-044067647f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1001 fhv_tripdata_2019-10.csv > head.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8948b26-6715-4104-9c05-24d58ef92727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = pd.read_csv('head.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab8194fe-28b5-466a-948e-4e304703f065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num       object\n",
       "pickup_datetime            object\n",
       "dropOff_datetime           object\n",
       "PUlocationID              float64\n",
       "DOlocationID              float64\n",
       "SR_Flag                   float64\n",
       "Affiliated_base_number     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c2b91",
   "metadata": {},
   "source": [
    "Defining the schema and using it to read the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28f90c56-af51-47c0-8d7a-1f3a551df8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True),\n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "371933d2-31cd-47d5-94fe-7c50c3cea0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhv_tripdata_2019-10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e87f71",
   "metadata": {},
   "source": [
    "Repartitioning and writing data to `.parquet` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61db68f8-af0a-468d-8b1f-cf040b5a4d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0e2ad46-6caf-4016-bfe4-d74c8139bc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhv/2019/10/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805e0303",
   "metadata": {},
   "source": [
    "Obtaining the average `.parquet` file size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fca61993-3ca4-40a8-bcb8-9a3f3bf6cdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6542913.5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(os.path.getsize('fhv/2019/10/' + f) for f in os.listdir('fhv/2019/10/') if not f.startswith('.')) / 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4786a5a3",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde130f2",
   "metadata": {},
   "source": [
    "Re-reading data from `.parquet` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0739a9b4-e435-46ae-a0ba-2fb8c78eb7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('fhv/2019/10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "126e940c-a8e1-4654-a797-983008094498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34ae33dc-0caf-45e5-acb4-76e85d9bce59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02784|2019-10-01 09:55:38|2019-10-01 10:05:43|          89|          85|   null|                  null|\n",
      "|              B01315|2019-10-05 15:13:04|2019-10-05 15:19:48|         264|          74|   null|                B01315|\n",
      "|              B01984|2019-10-12 17:13:00|2019-10-12 17:40:00|         264|          75|   null|                B01984|\n",
      "|              B00310|2019-10-15 10:55:04|2019-10-15 11:00:45|         264|         247|   null|                B03047|\n",
      "|              B00932|2019-10-08 06:58:42|2019-10-08 07:11:11|         264|          37|   null|                B00932|\n",
      "|              B01029|2019-10-10 14:45:00|2019-10-10 15:47:00|         264|         264|   null|                B01029|\n",
      "|              B01087|2019-10-14 18:41:24|2019-10-14 19:02:06|         261|         186|   null|                B01087|\n",
      "|              B03080|2019-10-05 14:49:10|2019-10-05 15:02:14|         264|          25|   null|                B02889|\n",
      "|              B03160|2019-10-10 12:50:00|2019-10-10 13:34:00|          77|          77|   null|                B02882|\n",
      "|              B02472|2019-10-16 14:12:36|2019-10-16 14:35:00|         264|         157|   null|                B02472|\n",
      "|              B01051|2019-10-05 22:06:46|2019-10-05 22:16:57|         264|         182|   null|                B01051|\n",
      "|              B02111|2019-10-08 14:58:52|2019-10-08 15:40:41|          98|          79|   null|                B02111|\n",
      "|              B00254|2019-10-03 20:33:11|2019-10-03 21:52:16|         246|         265|   null|                B02356|\n",
      "|              B00756|2019-10-16 10:58:00|2019-10-16 11:18:00|         264|         264|   null|                B00756|\n",
      "|              B02249|2019-10-04 19:55:49|2019-10-04 20:08:25|         264|         192|   null|                B02249|\n",
      "|              B03202|2019-10-13 07:39:33|2019-10-13 08:18:31|         264|         132|   null|                B03202|\n",
      "|              B00419|2019-10-11 08:33:12|2019-10-11 08:46:22|         182|         185|   null|                B00419|\n",
      "|              B02095|2019-10-09 11:16:00|2019-10-09 11:44:00|         264|         264|   null|                B02095|\n",
      "|              B02930|2019-10-05 22:06:15|2019-10-05 22:25:31|         264|          69|   null|                B02930|\n",
      "|              B01239|2019-10-07 20:08:15|2019-10-07 20:16:06|         264|          51|   null|                B02847|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ed107",
   "metadata": {},
   "source": [
    "Counting taxi trips on the 15th of October:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7e2e149-e3f3-4d6b-ab08-4ab4c7421c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.pickup_datetime.startswith('2019-10-15')).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee3f736",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63412be6",
   "metadata": {},
   "source": [
    "UDF to find the difference between two timestamps in hours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a4e0474-a8d9-44b6-98e5-4a659b2db327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_diff(*dt):\n",
    "    tstamp1 = dt[0]\n",
    "    tstamp2 = dt[1]\n",
    "    \n",
    "    if tstamp1 > tstamp2:\n",
    "        td = tstamp1 - tstamp2\n",
    "    else:\n",
    "        td = tstamp2 - tstamp1\n",
    "        \n",
    "    td_hours = float(round(td.total_seconds() / 3600, 2))\n",
    "    return td_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b9192e5-3eda-4a89-9b69-070184194d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_diff('2019-10-01 09:55:38', '2019-10-01 10:05:43')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82003572-5c6d-4586-b863-2979dac82567",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_diff_udf = F.udf(dt_diff, returnType=types.FloatType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed14231d",
   "metadata": {},
   "source": [
    "Applying the UDF to find the maximum trip duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eac45d2-fc15-4a62-9e15-9fbd3ead566e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:===========================================================(2 + 0) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|max(duration_hours)|\n",
      "+-------------------+\n",
      "|           631152.5|\n",
      "+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('duration_hours', dt_diff_udf(df.pickup_datetime, df.dropoff_datetime)) \\\n",
    "    .select(F.max('duration_hours')) \\\n",
    "    .show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7701ea25",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41667bca",
   "metadata": {},
   "source": [
    "Extracting zone data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cba4de28-6fdf-420d-82ef-38c3aadb5119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-22 09:43:11--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
      "Resolving github.com (github.com)... 192.30.255.112\n",
      "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240322%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240322T094311Z&X-Amz-Expires=300&X-Amz-Signature=5b4a4fc32010a6ec796849bafa0bafbd59adf03040cf9ad13fd5dea91c9e3635&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-22 09:43:11--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240322%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240322T094311Z&X-Amz-Expires=300&X-Amz-Signature=5b4a4fc32010a6ec796849bafa0bafbd59adf03040cf9ad13fd5dea91c9e3635&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi_zone_lookup.csv’\n",
      "\n",
      "taxi_zone_lookup.cs 100%[===================>]  12.03K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-22 09:43:12 (47.8 MB/s) - ‘taxi_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837f87f7",
   "metadata": {},
   "source": [
    "Reading zone data with Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c23c9a3-6bf4-4ef9-9b6a-db2cb3fb3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.csv('taxi_zone_lookup.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c617df98-702e-4568-a58a-8d8716a34903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a63c203",
   "metadata": {},
   "source": [
    "Registering temporary tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f20ae6b-8919-4e07-89c0-80ab398dde07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/volare/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('fhv')\n",
    "df_zones.registerTempTable('zones')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbbe4ac",
   "metadata": {},
   "source": [
    "Applying SQL query to find the least frequent pickup zone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8007ddb-bfa7-493c-9c54-7e72e6d9d5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|                Zone|pickup_zone_freq|\n",
      "+--------------------+----------------+\n",
      "|         Jamaica Bay|               1|\n",
      "|Governor's Island...|               2|\n",
      "| Green-Wood Cemetery|               5|\n",
      "|       Broad Channel|               8|\n",
      "|     Highbridge Park|              14|\n",
      "|        Battery Park|              15|\n",
      "|Saint Michaels Ce...|              23|\n",
      "|Breezy Point/Fort...|              25|\n",
      "|Marine Park/Floyd...|              26|\n",
      "|        Astoria Park|              29|\n",
      "|    Inwood Hill Park|              39|\n",
      "|       Willets Point|              47|\n",
      "|Forest Park/Highl...|              53|\n",
      "|  Brooklyn Navy Yard|              57|\n",
      "|        Crotona Park|              62|\n",
      "|        Country Club|              77|\n",
      "|     Freshkills Park|              89|\n",
      "|       Prospect Park|              98|\n",
      "|     Columbia Street|             105|\n",
      "|  South Williamsburg|             110|\n",
      "+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    zones.Zone, COUNT(1) AS pickup_zone_freq\n",
    "FROM\n",
    "    fhv\n",
    "LEFT JOIN\n",
    "    zones\n",
    "ON\n",
    "    fhv.PULocationID = zones.LocationID\n",
    "GROUP BY\n",
    "    zones.Zone\n",
    "ORDER BY pickup_zone_freq\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1bc55b-8598-462f-85e5-78322abea801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
